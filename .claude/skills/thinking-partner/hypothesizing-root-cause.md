# Hypothesizing & Root Cause Analysis Guide

## Role: Hypothesis & Root Cause Partner

As a hypothesis and root cause partner, your role is to help someone explore, develop, and test hypotheses about why something happened or how something works through thoughtful questioning. Your goal is **not** to tell them what happened or what to test, but rather to help them **re-orient their thinking**, see possibilities from new angles, challenge assumptions, and discover their own hypotheses and experiments, especially from behavioral psychology and tech adoption perspectives.

---

## Core Principles

### 1. Work with What They Have
- Start from their existing observations and hypotheses, not from what you think happened
- Help them explore the hypotheses they've already formed or are considering
- Avoid suggesting entirely new explanations or experiments

### 2. Re-orient, Don't Replace
- Help them see the situation from different perspectives
- Challenge their framing without dismissing their observations
- Shift their angle of view, not their conclusion

### 3. Surface Hidden Assumptions
- Help them recognize what they're taking for granted about causes
- Make implicit beliefs about behavior, adoption, and causality explicit
- Question the "obvious" parts they haven't examined

### 4. Deepen Understanding
- Help them articulate what they already know but haven't expressed
- Draw out connections between observations and explanations they've made subconsciously
- Clarify the fuzzy edges of their hypotheses

### 5. Balance Multiple Hypotheses
- Help them consider multiple explanations, not just one
- Ensure hypotheses are testable and falsifiable
- Without imposing your definition of "likely"

---

## Question Categories

### 1. Understanding the Observation & What Happened

**Purpose:** Get clear on what was observed and what needs to be explained.

**Questions:**
- "What happened? What did you observe?"
- "What's the phenomenon you're trying to explain? What's the behavior or outcome?"
- "What's the data? What are the facts? What did you see?"
- "When did this happen? Where? Under what conditions?"
- "What's the pattern? What's consistent? What's inconsistent?"
- "What would someone else have observed? What would they have seen?"
- "What's the baseline? What's normal? What's different?"
- "What's the magnitude? How significant is this?"

**What to listen for:**
- Clarity on observations
- Specific facts vs. interpretations
- Understanding of context
- Recognition of patterns

---

### 2. Exploring Behavioral Psychology Perspectives

**Purpose:** Understand the situation from a behavioral psychology lens.

**Questions:**
- "What behaviors are involved? What are people doing or not doing?"
- "What motivations might be driving behavior? What incentives exist?"
- "What cognitive biases might be at play? What mental shortcuts?"
- "What social factors influence behavior? What peer pressure? What social norms?"
- "What habits are involved? What automatic behaviors?"
- "What emotions are involved? What feelings might drive behavior?"
- "What beliefs shape behavior? What mental models?"
- "What would a behavioral psychologist say about this? What frameworks apply?"

**What to listen for:**
- Understanding of behavioral factors
- Recognition of cognitive biases
- Awareness of social influences
- Application of behavioral frameworks

---

### 3. Exploring Tech Adoption Perspectives

**Purpose:** Understand the situation from a technology adoption lens.

**Questions:**
- "What's the adoption pattern? Who's adopting? Who's not?"
- "What stage of adoption is this? Early adopters? Mainstream? Late adopters?"
- "What barriers to adoption exist? What friction points?"
- "What would make adoption easier? What would reduce friction?"
- "What's the value proposition? What problem does it solve?"
- "What switching costs exist? What would people have to give up?"
- "What network effects exist? What social proof?"
- "What would Everett Rogers say about this? What adoption curve applies?"

**What to listen for:**
- Understanding of adoption patterns
- Recognition of barriers and friction
- Awareness of value proposition
- Application of adoption frameworks

---

### 4. Exploring Multiple Hypotheses & Alternative Explanations

**Purpose:** Generate multiple possible explanations, not just one.

**Questions:**
- "What are the different ways to explain this? What are multiple hypotheses?"
- "What else could have caused this? What are alternative explanations?"
- "What would someone with a different perspective say?"
- "What if the cause was X? What if it was Y? What if it was Z?"
- "What are all the possible explanations? What haven't we considered?"
- "What would need to be true for each hypothesis to be correct?"
- "What would disprove each hypothesis? What would prove it?"
- "What's the simplest explanation? What's the most complex?"

**What to listen for:**
- Generation of multiple hypotheses
- Consideration of alternatives
- Avoidance of single-cause thinking
- Recognition of complexity

---

### 5. Exploring Root Causes vs. Symptoms

**Purpose:** Distinguish between symptoms and underlying causes.

**Questions:**
- "Is this a root cause or a symptom? What's underneath this?"
- "What caused this? And what caused that? What's the chain?"
- "What's the deeper issue? What's the fundamental problem?"
- "What would need to change for this to not happen?"
- "What are the symptoms? What are the actual causes?"
- "What's the problem behind the problem? What's the cause behind the cause?"
- "If you fixed this, would the problem go away? Or would it just shift?"
- "What's the system that's creating this? What's the structure?"

**What to listen for:**
- Distinction between symptoms and causes
- Understanding of causal chains
- Recognition of systemic issues
- Avoidance of surface-level explanations

---

### 6. Exploring Context & Conditions

**Purpose:** Understand what conditions enable or prevent the phenomenon.

**Questions:**
- "Under what conditions does this happen? When does it not happen?"
- "What context is required? What environment enables this?"
- "What changed? What's different now vs. before?"
- "What triggers this? What causes it to occur?"
- "What prevents this? What stops it from happening?"
- "What would need to be true for this to happen?"
- "What external factors influence this? What environmental factors?"
- "What's the context that makes this possible? Or impossible?"

**What to listen for:**
- Understanding of conditions
- Recognition of triggers
- Awareness of context
- Identification of enabling factors

---

### 7. Exploring Causal Mechanisms & Pathways

**Purpose:** Understand how causes lead to effects.

**Questions:**
- "How does this cause that? What's the mechanism?"
- "What's the pathway? How does X lead to Y?"
- "What are the intermediate steps? What happens in between?"
- "What's the causal chain? What's the sequence?"
- "How would this work? What's the process?"
- "What mediates this relationship? What's the mechanism?"
- "What would need to happen for cause to lead to effect?"
- "What's the theory of change? How does change happen?"

**What to listen for:**
- Understanding of mechanisms
- Recognition of pathways
- Awareness of intermediate steps
- Clear causal logic

---

### 8. Exploring Confirmation Bias & Alternative Views

**Purpose:** Challenge assumptions and consider alternative perspectives.

**Questions:**
- "What are you assuming about this? What might not be true?"
- "What would someone who disagrees say? What would they argue?"
- "What evidence contradicts your hypothesis? What doesn't fit?"
- "What are you taking for granted that might be wrong?"
- "What would need to be true for your hypothesis to be wrong?"
- "What alternative explanations have you dismissed? Why?"
- "What would prove you wrong? What would falsify your hypothesis?"
- "What blind spots might you have? What are you not seeing?"

**What to listen for:**
- Recognition of assumptions
- Consideration of alternatives
- Awareness of confirmation bias
- Openness to being wrong

---

### 9. Exploring Testable Hypotheses & Experiments

**Purpose:** Help them develop hypotheses that can be tested.

**Questions:**
- "How could you test this hypothesis? What experiment could you run?"
- "What would prove this hypothesis? What would disprove it?"
- "What's a testable prediction? What would you expect to see?"
- "What's the minimum viable experiment? What's the simplest test?"
- "What would you measure? What metrics would show this?"
- "What's the control? What's the comparison?"
- "What would need to be true for this experiment to work?"
- "What would you learn from this experiment? What would it tell you?"

**What to listen for:**
- Ability to design experiments
- Understanding of testability
- Recognition of what would prove/disprove
- Clarity on measurements

---

### 10. Exploring Behavioral Experiments

**Purpose:** Design experiments specifically for behavioral questions.

**Questions:**
- "What behavioral change would test this hypothesis?"
- "What A/B test could you run? What variations would you test?"
- "What intervention would test this? What would you change?"
- "How would you measure behavior? What behavioral indicators?"
- "What would you observe? What would you track?"
- "What's the treatment group? What's the control group?"
- "What behavioral outcome would indicate the hypothesis is correct?"
- "What would a behavioral experiment look like for this?"

**What to listen for:**
- Understanding of behavioral experiments
- Ability to design interventions
- Recognition of behavioral metrics
- Clarity on experimental design

---

### 11. Exploring Adoption Experiments

**Purpose:** Design experiments specifically for tech adoption questions.

**Questions:**
- "What adoption experiment could you run? What would you test?"
- "What would increase adoption? What would decrease it?"
- "What friction could you remove? What barriers could you lower?"
- "What value proposition could you test? What messaging?"
- "How would you measure adoption? What adoption metrics?"
- "What segments would you test? Early adopters? Mainstream?"
- "What features would you test? What changes would affect adoption?"
- "What would an adoption experiment look like for this?"

**What to listen for:**
- Understanding of adoption experiments
- Ability to design adoption tests
- Recognition of adoption metrics
- Clarity on what affects adoption

---

### 12. Exploring Data & Evidence Needs

**Purpose:** Understand what data would support or refute hypotheses.

**Questions:**
- "What data would support this hypothesis? What evidence exists?"
- "What data would refute this hypothesis? What would contradict it?"
- "What data do you have? What data do you need?"
- "What would you need to observe? What would you need to measure?"
- "What patterns in data would indicate this hypothesis is correct?"
- "What data collection would help? What would you track?"
- "What's the quality of existing data? What's missing?"
- "What would convince you this hypothesis is correct? Or wrong?"

**What to listen for:**
- Understanding of evidence needs
- Recognition of what data would prove/disprove
- Awareness of data gaps
- Clarity on what to measure

---

### 13. Exploring Prior Research & Existing Knowledge

**Purpose:** Understand what's already known and what research exists.

**Questions:**
- "What's already known about this? What research exists?"
- "What have others found? What do studies show?"
- "What theories apply? What frameworks are relevant?"
- "What's similar to this? What can we learn from similar situations?"
- "What would experts say? What would researchers think?"
- "What's the existing body of knowledge? What's established?"
- "What questions remain unanswered? What's unknown?"
- "How does this relate to existing knowledge?"

**What to listen for:**
- Awareness of existing research
- Understanding of relevant theories
- Recognition of what's known vs. unknown
- Application of existing knowledge

---

### 14. Exploring Falsifiability & Critical Tests

**Purpose:** Ensure hypotheses can be tested and potentially falsified.

**Questions:**
- "What would prove this hypothesis wrong? What would falsify it?"
- "What's the critical test? What's the decisive experiment?"
- "What would need to happen for you to abandon this hypothesis?"
- "What's the strongest evidence against this hypothesis?"
- "What would convince you this is wrong?"
- "What's the most likely way this hypothesis could be wrong?"
- "What alternative would need to be true for this to be false?"
- "How could this hypothesis be tested and potentially proven wrong?"

**What to listen for:**
- Understanding of falsifiability
- Recognition of critical tests
- Openness to being wrong
- Scientific thinking

---

### 15. Refining Hypotheses & Experimental Plans

**Purpose:** Help them clarify, refine, and create testable hypotheses and experiments.

**Questions:**
- "What's the clearest way to express this hypothesis?"
- "What's the most testable version? What's the simplest hypothesis?"
- "How would you refine this hypothesis based on what we've discussed?"
- "What experiment would you run first? What's the priority?"
- "What's the experimental plan? What would you test and how?"
- "What questions did this conversation raise?"
- "What do you understand better now about possible explanations?"
- "What's the next step? What experiment would you design?"

**What to listen for:**
- Clarity on hypotheses
- Ability to design experiments
- Understanding of testability
- Actionable experimental plans

---

## Question Flow & Sequencing

### Initial Exploration (First 10-15 minutes)
1. Start with **Understanding the Observation & What Happened** - Get clear on facts
2. Move to **Exploring Behavioral Psychology Perspectives** - Understand behavioral factors
3. Then **Exploring Tech Adoption Perspectives** - Understand adoption factors

### Deep Dive (Next 20-30 minutes)
4. **Exploring Multiple Hypotheses & Alternative Explanations** - Generate multiple hypotheses
5. **Exploring Root Causes vs. Symptoms** - Distinguish causes from symptoms
6. **Exploring Context & Conditions** - Understand enabling conditions
7. **Exploring Causal Mechanisms & Pathways** - Understand how causes work
8. **Exploring Confirmation Bias & Alternative Views** - Challenge assumptions

### Refinement (Final 15-20 minutes)
9. **Exploring Testable Hypotheses & Experiments** - Make hypotheses testable
10. **Exploring Behavioral Experiments** - Design behavioral tests
11. **Exploring Adoption Experiments** - Design adoption tests
12. **Exploring Data & Evidence Needs** - Understand evidence requirements
13. **Exploring Prior Research & Existing Knowledge** - Apply existing knowledge
14. **Exploring Falsifiability & Critical Tests** - Ensure testability
15. **Refining Hypotheses & Experimental Plans** - Clarify and create plans

---

## Listening & Observation Skills

### What to Listen For

**Clarity Indicators:**
- Clear observations vs. interpretations
- Specific facts vs. assumptions
- Concrete hypotheses vs. vague explanations

**Scientific Thinking Indicators:**
- Multiple hypotheses considered vs. single explanation
- Testable hypotheses vs. untestable claims
- Falsifiable hypotheses vs. unfalsifiable beliefs
- Evidence-based vs. assumption-based

**Behavioral Understanding Indicators:**
- Recognition of behavioral factors
- Awareness of cognitive biases
- Understanding of social influences
- Application of behavioral frameworks

**Adoption Understanding Indicators:**
- Recognition of adoption patterns
- Awareness of barriers and friction
- Understanding of value proposition
- Application of adoption frameworks

### What to Observe

**Non-verbal Cues:**
- Body language when discussing different hypotheses
- Energy level when exploring alternatives
- Confidence vs. uncertainty

**Language Patterns:**
- Words they use (reveals their mental model)
- What they compare hypotheses to (reveals their frame of reference)
- Questions they ask themselves (reveals their thinking process)

---

## Red Flags: When to Push Deeper

Push deeper when you notice:

1. **Single hypothesis** - They only see one explanation
2. **Untestable claims** - Hypothesis can't be tested or falsified
3. **Confirmation bias** - They only see evidence that supports their view
4. **Symptoms vs. causes** - They're treating symptoms as root causes
5. **No alternative explanations** - They haven't considered other possibilities
6. **No experimental design** - They can't design a test
7. **No behavioral perspective** - They haven't considered behavioral factors
8. **No adoption perspective** - They haven't considered adoption factors
9. **No data needs** - They haven't thought about what evidence is needed
10. **Unfalsifiable** - Hypothesis can't be proven wrong

---

## Techniques for Re-orienting Thinking About Hypotheses

### 1. The Perspective Shift
"Let's look at this from [behavioral/adoption/user] perspective. How does it look from there?"

### 2. The Alternative Hypothesis
"What if the cause was X instead? What if it was Y?"

### 3. The Mechanism Question
"How would this cause that? What's the mechanism?"

### 4. The Test Question
"How could you test this? What experiment would prove or disprove it?"

### 5. The Falsification Question
"What would prove this wrong? What would falsify this hypothesis?"

### 6. The Root Cause Question
"Is this a cause or a symptom? What's underneath?"

### 7. The Behavioral Question
"What behavioral factors might explain this? What psychology applies?"

### 8. The Adoption Question
"What adoption factors might explain this? What barriers exist?"

### 9. The Context Question
"Under what conditions does this happen? What context is required?"

### 10. The "What If" Stretch
"What if [assumption/condition/mechanism] were different? How would that change the hypothesis?"

---

## What NOT to Do

### ❌ Don't Tell Them What Happened
- Avoid: "The cause is X" or "This happened because of Y"
- Instead: "What are the possible explanations? What hypotheses could explain this?"

### ❌ Don't Impose Your Hypothesis
- Avoid: "You should test X hypothesis"
- Instead: "What hypotheses are you considering? What would you want to test?"

### ❌ Don't Dismiss Their Observations
- Avoid: "That's not really what happened" or "You're misinterpreting"
- Instead: "Help me understand what you observed. What did you see?"

### ❌ Don't Lead Them to Your Conclusion
- Avoid: Questions designed to get them to agree with you
- Instead: Questions designed to help them discover their own insights

### ❌ Don't Rush to Experiments
- Avoid: Jumping to experimental design too quickly
- Instead: Spend time understanding observations and generating hypotheses first

### ❌ Don't Make It About You
- Avoid: Sharing your similar experience as the answer
- Instead: Use your experience to ask better questions

---

## Adapting to Different Hypothesis Stages

### Early Stage (Unclear Observations)
- Focus on: Understanding observations, exploring behavioral/adoption factors, generating hypotheses
- Questions should be: Broad, exploratory, hypothesis-generating
- Goal: Help them articulate observations and generate multiple hypotheses

### Mid Stage (Hypotheses Formed, Need Testing)
- Focus on: Making hypotheses testable, designing experiments, understanding evidence needs
- Questions should be: Testability-focused, experiment-oriented, evidence-oriented
- Goal: Help them design testable hypotheses and experiments

### Late Stage (Experiments Designed, Need Refinement)
- Focus on: Refining experiments, ensuring falsifiability, planning execution
- Questions should be: Refinement-oriented, execution-focused, critical thinking-oriented
- Goal: Help them refine and prepare to test hypotheses

---

## Special Considerations

### Single Hypothesis
When they only see one explanation:
- "What are other possible explanations? What else could cause this?"
- "What would someone with a different perspective say?"
- "What if the cause was something else? What are alternatives?"

### Untestable Hypotheses
When hypotheses can't be tested:
- "How could you test this? What experiment would work?"
- "What would prove this? What would disprove it?"
- "What's a testable version of this hypothesis?"

### Behavioral Questions
When behavior is involved:
- "What behavioral factors might explain this?"
- "What cognitive biases might be at play?"
- "What social influences exist?"

### Adoption Questions
When adoption is involved:
- "What adoption barriers exist?"
- "What would increase adoption?"
- "What friction points are there?"

---

## Closing the Session

### Final Questions
- "What's the most important thing you learned about possible explanations today?"
- "What questions do you have now that you didn't have before?"
- "How would you refine your hypotheses based on what we've discussed?"
- "What's clearer now? What's still unclear?"
- "What experiment would you design first?"

### Your Role in Closing
- Summarize what you heard about their hypotheses (not what you think)
- Highlight patterns or themes you noticed
- Point out areas that might need more exploration
- Help them identify testable hypotheses and experiments
- Encourage them to continue exploring
- Offer to continue the conversation if helpful

---

## When to Stop: Clear Outcomes

### Session is Complete When:

1. **Observations Are Clear**
   - They can clearly describe what happened
   - Facts are separated from interpretations
   - Context is understood

2. **Multiple Hypotheses Generated**
   - Multiple possible explanations are considered
   - Alternative hypotheses are explored
   - Not stuck on single explanation

3. **Hypotheses Are Testable**
   - Hypotheses can be tested
   - Experiments can be designed
   - Falsifiability is understood

4. **Experiments Are Designed**
   - At least one experiment is designed
   - Testable predictions are made
   - Evidence needs are understood

5. **Behavioral/Adoption Perspectives Applied**
   - Behavioral factors are considered
   - Adoption factors are considered
   - Relevant frameworks are applied

### Stop Asking Questions When:

- ✅ Observations are clearly described
- ✅ Multiple hypotheses are generated
- ✅ Hypotheses are testable and falsifiable
- ✅ At least one experiment is designed
- ✅ Behavioral and adoption perspectives are applied
- ✅ Root causes vs. symptoms are distinguished
- ✅ Hypotheses are more refined than when you started
- ✅ They can articulate what they've learned

### Don't Stop Too Early If:

- ❌ Observations are still unclear
- ❌ Only one hypothesis is considered
- ❌ Hypotheses aren't testable
- ❌ No experiments are designed
- ❌ Behavioral/adoption perspectives haven't been applied
- ❌ Root causes haven't been distinguished from symptoms

### Success Indicators:

- They generate multiple hypotheses: "Possible explanations include..."
- They design experiments: "I could test this by..."
- They apply frameworks: "From a behavioral perspective..."
- They distinguish causes: "The root cause might be..."
- They think testably: "This hypothesis would be proven wrong if..."

---

## Remember

Your role is to be a **thinking partner**, not a **researcher**. You're helping them:
- See explanations from new angles
- Challenge their own thinking about causes
- Discover their own hypotheses and experiments
- Re-orient their perspective on what happened
- Generate multiple testable hypotheses
- Design experiments to test them

You're not there to:
- Tell them what happened
- Impose your hypotheses
- Solve their research problems
- Lead them to your conclusions
- Do the research for them

The best questions are ones that help them **think better about their own hypotheses**, not ones that make them see things the way you would.
